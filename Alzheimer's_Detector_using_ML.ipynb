{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpiiJh9YJXuR",
        "outputId": "2a6e97c1-4309-4d4a-ed0d-87b3bdaa34d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing data...\n",
            "Training the Logistic Regression model...\n",
            "Evaluating the model...\n",
            "Model Accuracy: 0.88\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Nondemented       0.79      0.97      0.87        32\n",
            "    Demented       0.97      0.81      0.89        43\n",
            "\n",
            "    accuracy                           0.88        75\n",
            "   macro avg       0.88      0.89      0.88        75\n",
            "weighted avg       0.90      0.88      0.88        75\n",
            "\n",
            "\n",
            "--- Model Explainability ---\n",
            "Interpreting the model's coefficients:\n",
            "           Coefficient\n",
            "num__CDR      3.812860\n",
            "cat__M/F      0.687035\n",
            "num__ASF     -0.077939\n",
            "num__Age     -0.125597\n",
            "num__nWBV    -0.272523\n",
            "num__EDUC    -0.427096\n",
            "num__eTIV    -0.443344\n",
            "num__SES     -0.657163\n",
            "num__MMSE    -1.062584\n",
            "\n",
            "Explanation:\n",
            "A positive coefficient indicates that as the feature's value increases, the likelihood of the person being 'Demented' (1) increases.\n",
            "A negative coefficient indicates that as the feature's value increases, the likelihood of the person being 'Nondemented' (0) increases.\n",
            "The magnitude of the coefficient shows how much that feature influences the prediction. A larger magnitude means greater influence.\n",
            "\n",
            "This simple table allows you to explain which factors your model considers most important for its prediction.\n",
            "\n",
            "--- Example Prediction ---\n",
            "Prediction for the new patient: The model predicts the patient is 'Demented'.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3609576838.py:60: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['Group'] = df['Group'].replace({'Demented': 1, 'Nondemented': 0, 'Converted': 1})\n",
            "/tmp/ipython-input-3609576838.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['M/F'] = df['M/F'].replace({'M': 1, 'F': 0}) # Convert Male/Female to 1/0\n"
          ]
        }
      ],
      "source": [
        "# Project Title: Alzheimer's Disease Detection using Machine Learning\n",
        "# Author: [Samyak Kumar Bhardwaj]\n",
        "# Date: September 2025\n",
        "\n",
        "# =============================================================================\n",
        "\n",
        "# Step 1: Import necessary libraries\n",
        "# We use pandas for data manipulation, numpy for numerical operations,\n",
        "# and scikit-learn for machine learning tasks.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# =============================================================================\n",
        "# Step 2: Load the dataset\n",
        "# We load the data from the CSV file into a pandas DataFrame.\n",
        "# =============================================================================\n",
        "try:\n",
        "    df = pd.read_csv('oasis_longitudinal.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'oasis_longitudinal.csv' not found.\")\n",
        "    print(\"Please download the dataset from Kaggle and place it in this directory.\")\n",
        "    exit()\n",
        "\n",
        "# =============================================================================\n",
        "# Step 3: Data Preprocessing\n",
        "# =============================================================================\n",
        "print(\"Preprocessing data...\")\n",
        "\n",
        "# Dropping columns that are not useful for our model\n",
        "# 'Subject ID' and 'MRI ID' are unique identifiers, not features.\n",
        "# 'Hand' has a single value 'R' for all entries, so it's not useful for prediction.\n",
        "df.drop(['Subject ID', 'MRI ID', 'Hand'], axis=1, inplace=True)\n",
        "\n",
        "# Handle missing values: We will fill missing values in 'SES' (Socioeconomic Status)\n",
        "# and 'MMSE' (Mini-Mental State Examination) columns with the median value.\n",
        "# The SimpleImputer in the pipeline will handle this automatically.\n",
        "\n",
        "# Converting categorical features to numerical\n",
        "# The 'Group' column (target variable) has 'Demented' and 'Nondemented' as text.\n",
        "# We convert them to 1 and 0, which is required for our model.\n",
        "df['Group'] = df['Group'].replace({'Demented': 1, 'Nondemented': 0, 'Converted': 1})\n",
        "df['M/F'] = df['M/F'].replace({'M': 1, 'F': 0}) # Convert Male/Female to 1/0\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "# X contains the input features (e.g., Age, EDUC, MMSE), and y is what we want to predict (Demented or not).\n",
        "X = df.drop('Group', axis=1)\n",
        "y = df['Group']\n",
        "\n",
        "# Defining a list of numerical and categorical features\n",
        "# This helps us apply different preprocessing steps to different types of data.\n",
        "numerical_features = ['Age', 'EDUC', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF']\n",
        "categorical_features = ['M/F']\n",
        "\n",
        "# Create a preprocessing pipeline\n",
        "# A pipeline combines multiple steps into a single object. This makes the code\n",
        "# cleaner and prevents data leakage (using information from the test set during training).\n",
        "# For numerical features, we fill missing values with the median and then scale the data.\n",
        "# For categorical features, we simply fill missing values with the most frequent value.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numerical_features),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent'))\n",
        "        ]), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "# We use 80% of the data for training the model and 20% for testing its performance.\n",
        "# This ensures that our model is evaluated on data it has never seen before.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# =============================================================================\n",
        "# Step 4: Model Training\n",
        "# We use Logistic Regression, a simple and highly interpretable model.\n",
        "# It's a great choice because we can easily explain how each feature contributes\n",
        "# to the final prediction.\n",
        "# =============================================================================\n",
        "print(\"Training the Logistic Regression model...\")\n",
        "\n",
        "# Create the final model pipeline\n",
        "# This pipeline first applies the preprocessing steps and then trains the model.\n",
        "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                 ('classifier', LogisticRegression(solver='liblinear', random_state=42))])\n",
        "\n",
        "# Train the model on the training data\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# =============================================================================\n",
        "# Step 5: Model Evaluation\n",
        "# We test the model's performance on the unseen data (test set).\n",
        "# =============================================================================\n",
        "print(\"Evaluating the model...\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Print a detailed classification report\n",
        "# This report gives more insight into the model's performance for each class.\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Nondemented', 'Demented']))\n",
        "\n",
        "# =============================================================================\n",
        "# Step 6: Explainability - Interpreting the Results\n",
        "# =============================================================================\n",
        "print(\"\\n--- Model Explainability ---\")\n",
        "print(\"Interpreting the model's coefficients:\")\n",
        "\n",
        "# Get the trained classifier from the pipeline\n",
        "classifier = model_pipeline.named_steps['classifier']\n",
        "\n",
        "# Get the names of the features after preprocessing\n",
        "feature_names_out = model_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
        "\n",
        "# Create a DataFrame to easily view the coefficients\n",
        "coefficients = pd.DataFrame(data=classifier.coef_[0], index=feature_names_out, columns=['Coefficient'])\n",
        "coefficients.sort_values(by='Coefficient', ascending=False, inplace=True)\n",
        "\n",
        "print(coefficients)\n",
        "\n",
        "# Explanation of coefficients:\n",
        "print(\"\\nExplanation:\")\n",
        "print(\"A positive coefficient indicates that as the feature's value increases, the likelihood of the person being 'Demented' (1) increases.\")\n",
        "print(\"A negative coefficient indicates that as the feature's value increases, the likelihood of the person being 'Nondemented' (0) increases.\")\n",
        "print(\"The magnitude of the coefficient shows how much that feature influences the prediction. A larger magnitude means greater influence.\")\n",
        "print(\"\\nThis simple table allows you to explain which factors your model considers most important for its prediction.\")\n",
        "\n",
        "# For example, you can see that a higher 'MMSE' score (cognitive test) has a\n",
        "# negative coefficient, which means a higher score makes the model\n",
        "# less likely to predict dementia, which makes perfect clinical sense!\n",
        "# Conversely, a higher 'Age' has a positive coefficient, indicating that age is a\n",
        "# key risk factor.\n",
        "\n",
        "# =============================================================================\n",
        "# Step 7: Simple Prediction Example\n",
        "# creating a new, hypothetical patient's data to test the model in a practical way.\n",
        "# =============================================================================\n",
        "print(\"\\n--- Example Prediction ---\")\n",
        "# Example data for a new patient\n",
        "new_patient = pd.DataFrame([{\n",
        "    'M/F': 1, # Using 1 for Male\n",
        "    'Age': 75,\n",
        "    'EDUC': 12,\n",
        "    'SES': 2,\n",
        "    'MMSE': 25,\n",
        "    'CDR': 0.5,\n",
        "    'eTIV': 1600,\n",
        "    'nWBV': 0.75,\n",
        "    'ASF': 1.10\n",
        "}])\n",
        "\n",
        "# Make the prediction\n",
        "prediction = model_pipeline.predict(new_patient)\n",
        "\n",
        "# Interpret the prediction\n",
        "prediction_label = 'Demented' if prediction[0] == 1 else 'Nondemented'\n",
        "print(f\"Prediction for the new patient: The model predicts the patient is '{prediction_label}'.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
